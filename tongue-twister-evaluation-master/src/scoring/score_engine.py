# -*- coding: utf-8 -*-
"""
è¯„åˆ†å¼•æ“æ¨¡å—

è¿™ä¸ªæ¨¡å—è´Ÿè´£å¤„ç†è®¯é£APIè¿”å›çš„è¯„æµ‹ç»“æœï¼Œè®¡ç®—ç»¼åˆå¾—åˆ†ï¼Œ
å¹¶ç”Ÿæˆç”¨æˆ·å‹å¥½çš„åé¦ˆä¿¡æ¯ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. è§£æè®¯é£APIè¯„æµ‹ç»“æœ
2. è®¡ç®—ç»¼åˆå¾—åˆ†å’Œå„ç»´åº¦å¾—åˆ†
3. ç”Ÿæˆè¯¦ç»†çš„å‘éŸ³åé¦ˆ
4. æä¾›æ”¹è¿›å»ºè®®
5. å†å²æˆç»©è·Ÿè¸ª

è¯„åˆ†ç»´åº¦è¯´æ˜ï¼š
- å‘éŸ³å‡†ç¡®åº¦ï¼ˆpronunciationï¼‰ï¼šéŸ³ç´ å‘éŸ³çš„å‡†ç¡®æ€§
- æµåˆ©åº¦ï¼ˆfluencyï¼‰ï¼šè¯­é€Ÿå’Œåœé¡¿çš„è‡ªç„¶æ€§
- å®Œæ•´åº¦ï¼ˆintegrityï¼‰ï¼šæ˜¯å¦å®Œæ•´è¯»å®Œ
- è¯­è°ƒï¼ˆtoneï¼‰ï¼šå£°è°ƒçš„å‡†ç¡®æ€§ï¼ˆä¸­æ–‡ç‰¹æœ‰ï¼‰
"""

import json
import math
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import logging

@dataclass
class WordScore:
    """å•è¯è¯„åˆ†ç»“æœ"""
    word: str                    # è¯è¯­
    pronunciation_score: float   # å‘éŸ³å¾—åˆ†
    tone_score: float           # å£°è°ƒå¾—åˆ†
    is_correct: bool            # æ˜¯å¦æ­£ç¡®
    error_type: Optional[str]   # é”™è¯¯ç±»å‹
    phonemes: List[Dict]        # éŸ³ç´ è¯¦æƒ…

@dataclass
class SentenceScore:
    """å¥å­è¯„åˆ†ç»“æœ"""
    text: str                   # åŸæ–‡
    overall_score: float        # æ€»åˆ†
    pronunciation_score: float  # å‘éŸ³å¾—åˆ†
    fluency_score: float       # æµåˆ©åº¦å¾—åˆ†
    integrity_score: float     # å®Œæ•´åº¦å¾—åˆ†
    tone_score: float          # å£°è°ƒå¾—åˆ†
    word_scores: List[WordScore] # è¯è¯­å¾—åˆ†åˆ—è¡¨
    duration: float            # æœ—è¯»æ—¶é•¿
    speed_score: float         # è¯­é€Ÿå¾—åˆ†

@dataclass
class EvaluationResult:
    """å®Œæ•´è¯„æµ‹ç»“æœ"""
    sentence_score: SentenceScore
    grade_level: str           # ç­‰çº§ï¼ˆä¼˜ç§€/è‰¯å¥½/åŠæ ¼/éœ€æ”¹è¿›ï¼‰
    feedback_summary: str      # æ€»ä½“åé¦ˆ
    detailed_feedback: List[str] # è¯¦ç»†åé¦ˆ
    improvement_tips: List[str]  # æ”¹è¿›å»ºè®®
    timestamp: datetime        # è¯„æµ‹æ—¶é—´
    raw_result: Dict[str, Any] # åŸå§‹ç»“æœ

class ScoreEngine:
    """è¯„åˆ†å¼•æ“
    
    è´Ÿè´£å¤„ç†å’Œåˆ†æè¯­éŸ³è¯„æµ‹ç»“æœ
    """
    
    # ç­‰çº§åˆ’åˆ†æ ‡å‡†ï¼ˆæ›´ä¸¥æ ¼çš„è¯„åˆ¤æ ‡å‡†ï¼‰
    GRADE_THRESHOLDS = {
        'ä¼˜ç§€': 95,
        'è‰¯å¥½': 85,
        'åŠæ ¼': 75,
        'éœ€æ”¹è¿›': 0
    }
    
    # å„ç»´åº¦æƒé‡ï¼ˆæé«˜å‘éŸ³å‡†ç¡®åº¦æƒé‡ï¼‰
    DIMENSION_WEIGHTS = {
        'pronunciation': 0.5,  # å‘éŸ³å‡†ç¡®åº¦æƒé‡50%ï¼ˆæé«˜ï¼‰
        'fluency': 0.2,       # æµåˆ©åº¦æƒé‡20%ï¼ˆé™ä½ï¼‰
        'integrity': 0.15,    # å®Œæ•´åº¦æƒé‡15%ï¼ˆé™ä½ï¼‰
        'tone': 0.15          # å£°è°ƒæƒé‡15%ï¼ˆä¿æŒï¼‰
    }
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.history = []  # å†å²è¯„æµ‹è®°å½•
    
    def process_evaluation_result(self, raw_result: Dict[str, Any], 
                                text: str, duration: float = 0) -> EvaluationResult:
        """å¤„ç†è¯„æµ‹ç»“æœ
        
        Args:
            raw_result: è®¯é£APIè¿”å›çš„åŸå§‹ç»“æœ
            text: åŸå§‹æ–‡æœ¬
            duration: æœ—è¯»æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            å¤„ç†åçš„è¯„æµ‹ç»“æœ
        """
        try:
            # 1. è§£æåŸºç¡€å¾—åˆ†
            sentence_score = self._parse_sentence_score(raw_result, text, duration)
            
            # 2. è®¡ç®—ç­‰çº§
            grade_level = self._calculate_grade(sentence_score.overall_score)
            
            # 3. ç”Ÿæˆåé¦ˆ
            feedback_summary = self._generate_feedback_summary(sentence_score)
            detailed_feedback = self._generate_detailed_feedback(sentence_score)
            improvement_tips = self._generate_improvement_tips(sentence_score)
            
            # 4. åˆ›å»ºå®Œæ•´ç»“æœ
            result = EvaluationResult(
                sentence_score=sentence_score,
                grade_level=grade_level,
                feedback_summary=feedback_summary,
                detailed_feedback=detailed_feedback,
                improvement_tips=improvement_tips,
                timestamp=datetime.now(),
                raw_result=raw_result
            )
            
            # 5. è®°å½•åˆ°å†å²
            self.history.append(result)
            
            self.logger.info(f"è¯„æµ‹ç»“æœå¤„ç†å®Œæˆï¼Œæ€»åˆ†: {sentence_score.overall_score:.1f}")
            return result
            
        except Exception as e:
            self.logger.error(f"å¤„ç†è¯„æµ‹ç»“æœå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            return self._create_default_result(text, raw_result)
    
    def _parse_sentence_score(self, raw_result: Dict[str, Any], 
                            text: str, duration: float) -> SentenceScore:
        """è§£æå¥å­å¾—åˆ†
        
        Args:
            raw_result: åŸå§‹ç»“æœ
            text: åŸæ–‡
            duration: æ—¶é•¿
            
        Returns:
            å¥å­å¾—åˆ†å¯¹è±¡
        """
        # æå–åŸºç¡€å¾—åˆ†ï¼ˆè®¯é£APIå·²ç»å¤„ç†è¿‡çš„å¾—åˆ†ï¼‰
        overall_score = raw_result.get('overall_score', 0)
        pronunciation_score = raw_result.get('pronunciation_score', 0)
        fluency_score = raw_result.get('fluency_score', 0)
        integrity_score = raw_result.get('integrity_score', 0)
        tone_score = raw_result.get('tone_score', 0)
        
        # è§£æè¯è¯­è¯¦æƒ…
        word_scores = self._parse_word_scores(raw_result.get('word_details', []))
        
        # è®¡ç®—è¯­é€Ÿå¾—åˆ†
        speed_score = self._calculate_speed_score(text, duration)
        
        # æ€»æ˜¯ä½¿ç”¨åŠ æƒè®¡ç®—æ¥ç¡®ä¿æ€»åˆ†çš„å‡†ç¡®æ€§
        # å¦‚æœå„ç»´åº¦å¾—åˆ†éƒ½å­˜åœ¨ï¼Œé‡æ–°è®¡ç®—æ€»åˆ†
        if any([pronunciation_score, fluency_score, integrity_score, tone_score]):
            calculated_score = self._calculate_weighted_score(
                pronunciation_score, fluency_score, integrity_score, tone_score
            )
            # ä½¿ç”¨è®¡ç®—å‡ºçš„åˆ†æ•°ï¼Œé™¤éAPIè¿”å›çš„æ€»åˆ†æ˜æ˜¾æ›´åˆç†
            if overall_score == 0 or abs(calculated_score - overall_score) > 20:
                overall_score = calculated_score
                self.logger.info(f"ä½¿ç”¨åŠ æƒè®¡ç®—æ€»åˆ†: {overall_score:.1f} (APIè¿”å›: {raw_result.get('overall_score', 0)})")
            else:
                # å¦‚æœå·®å¼‚ä¸å¤§ï¼Œä½¿ç”¨APIè¿”å›çš„åˆ†æ•°
                overall_score = overall_score
        
        return SentenceScore(
            text=text,
            overall_score=overall_score,
            pronunciation_score=pronunciation_score,
            fluency_score=fluency_score,
            integrity_score=integrity_score,
            tone_score=tone_score,
            word_scores=word_scores,
            duration=duration,
            speed_score=speed_score
        )
    
    def _parse_word_scores(self, word_details: List[Dict]) -> List[WordScore]:
        """è§£æè¯è¯­å¾—åˆ†è¯¦æƒ…
        
        Args:
            word_details: è¯è¯­è¯¦æƒ…åˆ—è¡¨
            
        Returns:
            è¯è¯­å¾—åˆ†åˆ—è¡¨
        """
        word_scores = []
        
        for word_data in word_details:
            try:
                word_score = WordScore(
                    word=word_data.get('word', ''),
                    pronunciation_score=word_data.get('phone_score', 0),
                    tone_score=word_data.get('tone_score', 0),
                    is_correct=word_data.get('is_correct', True),
                    error_type=word_data.get('error_type'),
                    phonemes=word_data.get('phonemes', [])
                )
                word_scores.append(word_score)
                
            except Exception as e:
                self.logger.warning(f"è§£æè¯è¯­å¾—åˆ†å¤±è´¥: {e}")
                continue
        
        return word_scores
    
    def _calculate_speed_score(self, text: str, duration: float) -> float:
        """è®¡ç®—è¯­é€Ÿå¾—åˆ†
        
        Args:
            text: æ–‡æœ¬
            duration: æ—¶é•¿
            
        Returns:
            è¯­é€Ÿå¾—åˆ†ï¼ˆ0-100ï¼‰
        """
        if duration <= 0:
            return 0
        
        # è®¡ç®—å­—ç¬¦æ•°ï¼ˆä¸­æ–‡æŒ‰å­—è®¡ç®—ï¼‰
        char_count = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
        
        if char_count == 0:
            return 0
        
        # è®¡ç®—è¯­é€Ÿï¼ˆå­—/ç§’ï¼‰
        speed = char_count / duration
        
        # ç†æƒ³è¯­é€ŸèŒƒå›´ï¼š2-4å­—/ç§’
        ideal_min = 2.0
        ideal_max = 4.0
        
        if ideal_min <= speed <= ideal_max:
            # åœ¨ç†æƒ³èŒƒå›´å†…ï¼Œå¾—åˆ†100
            return 100
        elif speed < ideal_min:
            # è¿‡æ…¢ï¼ŒæŒ‰æ¯”ä¾‹æ‰£åˆ†
            return max(0, (speed / ideal_min) * 100)
        else:
            # è¿‡å¿«ï¼ŒæŒ‰æ¯”ä¾‹æ‰£åˆ†
            excess_ratio = (speed - ideal_max) / ideal_max
            return max(0, 100 - excess_ratio * 50)
    
    def _calculate_weighted_score(self, pronunciation: float, fluency: float, 
                                integrity: float, tone: float) -> float:
        """è®¡ç®—åŠ æƒæ€»åˆ†
        
        Args:
            pronunciation: å‘éŸ³å¾—åˆ†
            fluency: æµåˆ©åº¦å¾—åˆ†
            integrity: å®Œæ•´åº¦å¾—åˆ†
            tone: å£°è°ƒå¾—åˆ†
            
        Returns:
            åŠ æƒæ€»åˆ†
        """
        weighted_score = (
            pronunciation * self.DIMENSION_WEIGHTS['pronunciation'] +
            fluency * self.DIMENSION_WEIGHTS['fluency'] +
            integrity * self.DIMENSION_WEIGHTS['integrity'] +
            tone * self.DIMENSION_WEIGHTS['tone']
        )
        
        return round(weighted_score, 1)
    
    def _calculate_grade(self, score: float) -> str:
        """è®¡ç®—ç­‰çº§
        
        Args:
            score: æ€»åˆ†
            
        Returns:
            ç­‰çº§å­—ç¬¦ä¸²
        """
        for grade, threshold in self.GRADE_THRESHOLDS.items():
            if score >= threshold:
                return grade
        return 'éœ€æ”¹è¿›'
    
    def _generate_feedback_summary(self, sentence_score: SentenceScore) -> str:
        """ç”Ÿæˆæ€»ä½“åé¦ˆ
        
        Args:
            sentence_score: å¥å­å¾—åˆ†
            
        Returns:
            åé¦ˆæ‘˜è¦
        """
        score = sentence_score.overall_score
        
        if score >= 95:
            return f"å¤ªæ£’äº†ï¼ä½ çš„å‘éŸ³éå¸¸æ ‡å‡†ï¼Œæ€»åˆ†{score:.1f}åˆ†ï¼Œç»§ç»­ä¿æŒï¼"
        elif score >= 85:
            return f"å¾ˆä¸é”™ï¼ä½ çš„å‘éŸ³åŸºæœ¬å‡†ç¡®ï¼Œæ€»åˆ†{score:.1f}åˆ†ï¼Œè¿˜æœ‰æå‡ç©ºé—´ã€‚"
        elif score >= 75:
            return f"è¿˜å¯ä»¥ï¼ä½ çš„å‘éŸ³åˆšåˆšåŠæ ¼ï¼Œæ€»åˆ†{score:.1f}åˆ†ï¼Œéœ€è¦å¤šç»ƒä¹ ã€‚"
        else:
            return f"éœ€è¦åŠ æ²¹ï¼æ€»åˆ†{score:.1f}åˆ†ï¼Œå‘éŸ³è¿˜æœ‰å¾ˆå¤§æ”¹è¿›ç©ºé—´ï¼Œå»ºè®®å¤šå¬å¤šç»ƒï¼"
    
    def _generate_detailed_feedback(self, sentence_score: SentenceScore) -> List[str]:
        """ç”Ÿæˆè¯¦ç»†åé¦ˆ
        
        Args:
            sentence_score: å¥å­å¾—åˆ†
            
        Returns:
            è¯¦ç»†åé¦ˆåˆ—è¡¨
        """
        feedback = []
        
        # å‘éŸ³å‡†ç¡®åº¦åé¦ˆ
        if sentence_score.pronunciation_score >= 85:
            feedback.append(f"ğŸ¯ å‘éŸ³å‡†ç¡®åº¦å¾ˆé«˜ï¼ˆ{sentence_score.pronunciation_score:.1f}åˆ†ï¼‰")
        elif sentence_score.pronunciation_score >= 70:
            feedback.append(f"ğŸ“¢ å‘éŸ³åŸºæœ¬å‡†ç¡®ï¼ˆ{sentence_score.pronunciation_score:.1f}åˆ†ï¼‰ï¼Œä¸ªåˆ«å­—éŸ³éœ€è¦æ³¨æ„")
        else:
            feedback.append(f"ğŸ”¤ å‘éŸ³éœ€è¦æ”¹è¿›ï¼ˆ{sentence_score.pronunciation_score:.1f}åˆ†ï¼‰ï¼Œå»ºè®®å¤šå¬æ ‡å‡†å‘éŸ³")
        
        # æµåˆ©åº¦åé¦ˆ
        if sentence_score.fluency_score >= 85:
            feedback.append(f"ğŸŒŠ æœ—è¯»å¾ˆæµåˆ©ï¼ˆ{sentence_score.fluency_score:.1f}åˆ†ï¼‰")
        elif sentence_score.fluency_score >= 70:
            feedback.append(f"â±ï¸ æœ—è¯»åŸºæœ¬æµåˆ©ï¼ˆ{sentence_score.fluency_score:.1f}åˆ†ï¼‰ï¼Œæ³¨æ„è¯­é€Ÿå’Œåœé¡¿")
        else:
            feedback.append(f"ğŸŒ æœ—è¯»ä¸å¤Ÿæµåˆ©ï¼ˆ{sentence_score.fluency_score:.1f}åˆ†ï¼‰ï¼Œå»ºè®®å¤šç»ƒä¹ ")
        
        # å®Œæ•´åº¦åé¦ˆ
        if sentence_score.integrity_score >= 90:
            feedback.append(f"âœ… æœ—è¯»å¾ˆå®Œæ•´ï¼ˆ{sentence_score.integrity_score:.1f}åˆ†ï¼‰")
        elif sentence_score.integrity_score >= 70:
            feedback.append(f"ğŸ“ æœ—è¯»åŸºæœ¬å®Œæ•´ï¼ˆ{sentence_score.integrity_score:.1f}åˆ†ï¼‰")
        else:
            feedback.append(f"âŒ æœ—è¯»ä¸å¤Ÿå®Œæ•´ï¼ˆ{sentence_score.integrity_score:.1f}åˆ†ï¼‰ï¼Œæœ‰é—æ¼æˆ–æ·»åŠ ")
        
        # å£°è°ƒåé¦ˆ
        if sentence_score.tone_score >= 85:
            feedback.append(f"ğŸµ å£°è°ƒå¾ˆå‡†ç¡®ï¼ˆ{sentence_score.tone_score:.1f}åˆ†ï¼‰")
        elif sentence_score.tone_score >= 70:
            feedback.append(f"ğŸ¼ å£°è°ƒåŸºæœ¬å‡†ç¡®ï¼ˆ{sentence_score.tone_score:.1f}åˆ†ï¼‰")
        else:
            feedback.append(f"ğŸ¶ å£°è°ƒéœ€è¦æ”¹è¿›ï¼ˆ{sentence_score.tone_score:.1f}åˆ†ï¼‰ï¼Œæ³¨æ„å››å£°å˜åŒ–")
        
        # è¯­é€Ÿåé¦ˆ
        if sentence_score.duration > 0:
            char_count = len([c for c in sentence_score.text if '\u4e00' <= c <= '\u9fff'])
            speed = char_count / sentence_score.duration
            
            if speed < 2:
                feedback.append(f"ğŸ¢ è¯­é€Ÿåæ…¢ï¼ˆ{speed:.1f}å­—/ç§’ï¼‰ï¼Œå¯ä»¥é€‚å½“åŠ å¿«")
            elif speed > 4:
                feedback.append(f"ğŸ° è¯­é€Ÿåå¿«ï¼ˆ{speed:.1f}å­—/ç§’ï¼‰ï¼Œå¯ä»¥é€‚å½“æ”¾æ…¢")
            else:
                feedback.append(f"â° è¯­é€Ÿåˆé€‚ï¼ˆ{speed:.1f}å­—/ç§’ï¼‰")
        
        return feedback
    
    def _generate_improvement_tips(self, sentence_score: SentenceScore) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®
        
        Args:
            sentence_score: å¥å­å¾—åˆ†
            
        Returns:
            æ”¹è¿›å»ºè®®åˆ—è¡¨
        """
        tips = []
        
        # æ ¹æ®æœ€è–„å¼±çš„ç»´åº¦ç»™å‡ºå»ºè®®
        scores = {
            'pronunciation': sentence_score.pronunciation_score,
            'fluency': sentence_score.fluency_score,
            'integrity': sentence_score.integrity_score,
            'tone': sentence_score.tone_score
        }
        
        # æ‰¾å‡ºå¾—åˆ†æœ€ä½çš„ç»´åº¦
        weakest_dimension = min(scores.keys(), key=lambda k: scores[k])
        
        if scores[weakest_dimension] < 80:
            if weakest_dimension == 'pronunciation':
                tips.extend([
                    "å¤šå¬æ ‡å‡†æ™®é€šè¯å‘éŸ³ï¼Œæ³¨æ„æ¨¡ä»¿",
                    "å¯ä»¥ä½¿ç”¨æ‹¼éŸ³è¾…åŠ©ï¼Œç¡®è®¤æ¯ä¸ªå­—çš„è¯»éŸ³",
                    "æ”¾æ…¢è¯­é€Ÿï¼Œç¡®ä¿æ¯ä¸ªéŸ³éƒ½å‘å‡†ç¡®"
                ])
            elif weakest_dimension == 'fluency':
                tips.extend([
                    "å…ˆç†Ÿè¯»æ–‡æœ¬ï¼Œç†è§£å†…å®¹åå†æœ—è¯»",
                    "æ³¨æ„è¯­å¥é—´çš„è‡ªç„¶åœé¡¿",
                    "ä¿æŒå‡åŒ€çš„è¯­é€Ÿï¼Œé¿å…å¿½å¿«å¿½æ…¢"
                ])
            elif weakest_dimension == 'integrity':
                tips.extend([
                    "æœ—è¯»å‰ä»”ç»†çœ‹æ¸…æ¯ä¸ªå­—",
                    "ä¸è¦è·³è¯»æˆ–æ·»åŠ é¢å¤–çš„å­—",
                    "å¦‚æœè¯»é”™äº†ï¼Œå¯ä»¥é‡æ–°å¼€å§‹"
                ])
            elif weakest_dimension == 'tone':
                tips.extend([
                    "æ³¨æ„ä¸­æ–‡çš„å››ä¸ªå£°è°ƒå˜åŒ–",
                    "å¯ä»¥å…ˆç»ƒä¹ å•ä¸ªå­—çš„å£°è°ƒ",
                    "å¬æ ‡å‡†å‘éŸ³ï¼Œæ³¨æ„å£°è°ƒçš„èµ·ä¼"
                ])
        
        # é’ˆå¯¹ç»•å£ä»¤çš„ç‰¹æ®Šå»ºè®®
        if any(char in sentence_score.text for char in ['å››', 'å', 'çŸ³', 'ç‹®']):
            tips.append("è¿™æ˜¯ç»å…¸çš„ç»•å£ä»¤ï¼Œé‡ç‚¹ç»ƒä¹ ç›¸ä¼¼éŸ³çš„åŒºåˆ†")
        
        # é€šç”¨å»ºè®®
        if sentence_score.overall_score < 70:
            tips.extend([
                "å»ºè®®æ¯å¤©ç»ƒä¹ 10-15åˆ†é’Ÿ",
                "å¯ä»¥å½•éŸ³å¯¹æ¯”ï¼Œå¬å¬è‡ªå·±çš„å‘éŸ³",
                "ä»ç®€å•çš„ç»•å£ä»¤å¼€å§‹ç»ƒä¹ "
            ])
        
        return tips[:5]  # æœ€å¤šè¿”å›5æ¡å»ºè®®
    
    def _create_default_result(self, text: str, raw_result: Dict) -> EvaluationResult:
        """åˆ›å»ºé»˜è®¤ç»“æœï¼ˆå½“è§£æå¤±è´¥æ—¶ï¼‰
        
        Args:
            text: åŸæ–‡
            raw_result: åŸå§‹ç»“æœ
            
        Returns:
            é»˜è®¤è¯„æµ‹ç»“æœ
        """
        default_sentence_score = SentenceScore(
            text=text,
            overall_score=0,
            pronunciation_score=0,
            fluency_score=0,
            integrity_score=0,
            tone_score=0,
            word_scores=[],
            duration=0,
            speed_score=0
        )
        
        return EvaluationResult(
            sentence_score=default_sentence_score,
            grade_level='éœ€æ”¹è¿›',
            feedback_summary='è¯„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜ï¼Œè¯·é‡æ–°å°è¯•',
            detailed_feedback=['æ— æ³•è·å–è¯¦ç»†è¯„åˆ†ä¿¡æ¯'],
            improvement_tips=['è¯·æ£€æŸ¥å½•éŸ³è´¨é‡ï¼Œç¡®ä¿å£°éŸ³æ¸…æ™°'],
            timestamp=datetime.now(),
            raw_result=raw_result
        )
    
    def get_progress_analysis(self, limit: int = 10) -> Dict[str, Any]:
        """è·å–è¿›æ­¥åˆ†æ
        
        Args:
            limit: åˆ†ææœ€è¿‘çš„è®°å½•æ•°é‡
            
        Returns:
            è¿›æ­¥åˆ†æç»“æœ
        """
        if not self.history:
            return {'message': 'æš‚æ— å†å²è®°å½•'}
        
        recent_results = self.history[-limit:]
        
        # è®¡ç®—å¹³å‡åˆ†å˜åŒ–
        scores = [result.sentence_score.overall_score for result in recent_results]
        
        if len(scores) < 2:
            return {
                'current_score': scores[0] if scores else 0,
                'message': 'éœ€è¦æ›´å¤šç»ƒä¹ è®°å½•æ‰èƒ½åˆ†æè¿›æ­¥æƒ…å†µ'
            }
        
        # è®¡ç®—è¶‹åŠ¿
        first_half = scores[:len(scores)//2]
        second_half = scores[len(scores)//2:]
        
        avg_first = sum(first_half) / len(first_half)
        avg_second = sum(second_half) / len(second_half)
        
        improvement = avg_second - avg_first
        
        analysis = {
            'total_attempts': len(recent_results),
            'current_score': scores[-1],
            'average_score': sum(scores) / len(scores),
            'best_score': max(scores),
            'improvement': improvement,
            'trend': 'ä¸Šå‡' if improvement > 2 else 'ä¸‹é™' if improvement < -2 else 'ç¨³å®š'
        }
        
        return analysis
    
    def export_history(self) -> List[Dict[str, Any]]:
        """å¯¼å‡ºå†å²è®°å½•
        
        Returns:
            å†å²è®°å½•åˆ—è¡¨
        """
        exported_data = []
        
        for result in self.history:
            exported_data.append({
                'timestamp': result.timestamp.isoformat(),
                'text': result.sentence_score.text,
                'overall_score': result.sentence_score.overall_score,
                'grade_level': result.grade_level,
                'pronunciation_score': result.sentence_score.pronunciation_score,
                'fluency_score': result.sentence_score.fluency_score,
                'integrity_score': result.sentence_score.integrity_score,
                'tone_score': result.sentence_score.tone_score,
                'duration': result.sentence_score.duration
            })
        
        return exported_data

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºè¯„åˆ†å¼•æ“
    engine = ScoreEngine()
    
    # æ¨¡æ‹Ÿè®¯é£APIè¿”å›çš„ç»“æœ
    mock_result = {
        'overall_score': 85.5,
        'pronunciation_score': 88.0,
        'fluency_score': 82.0,
        'integrity_score': 90.0,
        'tone_score': 83.0,
        'word_details': [
            {
                'word': 'å››æ˜¯å››',
                'phone_score': 85,
                'tone_score': 80,
                'is_correct': True
            }
        ]
    }
    
    # å¤„ç†ç»“æœ
    result = engine.process_evaluation_result(
        mock_result, 
        "å››æ˜¯å››ï¼Œåæ˜¯åï¼Œåå››æ˜¯åå››ï¼Œå››åæ˜¯å››å", 
        3.5
    )
    
    print(f"ç­‰çº§: {result.grade_level}")
    print(f"æ€»ä½“åé¦ˆ: {result.feedback_summary}")
    print("è¯¦ç»†åé¦ˆ:")
    for feedback in result.detailed_feedback:
        print(f"  - {feedback}")
    print("æ”¹è¿›å»ºè®®:")
    for tip in result.improvement_tips:
        print(f"  - {tip}")